#! /bin/bash

#We source the export file to include the $cluster_name varialbe in our script
source sources/export_file
###---We start the installation script first
bash sources/ceph_hammer_packages

#WE define our Variables
conf_file="/etc/ceph/"$cluster_name".conf"

#We find the IP adress on the server that we are working on
ip_addr="$(ifconfig eth1 | grep 'inet addr' | cut -d ':' -f 2 | cut -d ' ' -f 1)"


#We add the [mon.$HOSTNAME] section in the conf file
echo -e"\n[mon.$HOSTNAME]
host = $HOSTNAME
mon addr = $ip_addr:6789
mon data = /var/lib/ceph/mon/$cluster_name-$HOSTNAME
" >> $conf_file

###*******************************************create scp to send the .conf file to other servers ***********************************************

mon_name=( $(grep "mon data" $conf_file | cut -d"-" -f2) )

a=0
while [ $a -lt ${#mon_name[@]} ] 
do
#while the Increment is lower than the number of servers to send the conf file to, proceed
        if [ ${mon_name[a]} = $HOSTNAME ]
        then
                echo -e "\nWe cannot send this file to the '$HOSTNAME' server, since it already has it up to date\n"
                (( a++ ))
                continue
	#We first test that the result is not the server that we already are on, since we do not need to send the file to it
	#If result shows that it is the server that we already are on, it will skip its turn (with the continue command) and increment for the next value
        else
                if [[ "${mon_name[a]}" == compute* ]]    #the [[ ]] are needed for the regex wildcard "*"
                then
                        user_name="compute"
                        echo -e "\nThe username for the server '${mon_name[a]}' is $user_name\n"
                        scp $conf_file $user_name@${mon_name[a]}:/tmp
                        ssh -t $user_name@${mon_name[a]} "sudo mv /tmp/"$cluster_name".conf $conf_file | sudo chown root.root $conf_file"
		#if the HOSTNAME is any variant of compute* --> compute1, compute2, compute3, etc. We send the file to them
                elif [ "${mon_name[a]}" = controller ]
                then
                        user_name="controller"
                        echo -e "\nThe username for the server '${mon_name[a]}' is $user_name\n"
                        scp $conf_file $user_name@${mon_name[a]}:/tmp
                        ssh -t $user_name@${mon_name[a]} "sudo mv /tmp/"$cluster_name".conf $conf_file | sudo chown root.root $conf_file"
		#idem but for the controller
                else
                        echo -e "\nWe have not find any server matching our server list to send the $conf_file to"
			echo -e "This server : '${mon_name[a]}' is not known to us\n"
			read -p "Please enter the username: " user_name
			scp $conf_file $user_name@${mon_name[a]}:/tmp
                        ssh -t $user_name@${mon_name[a]} "sudo mv /tmp/"$cluster_name".conf $conf_file | sudo chown root.root $conf_file"
		#Just in case there is a HOSTNAME that we were not aware of in the conf file
                fi
        fi

        (( a++ ))
done

############################################################-END OF SCP-#####################################################################

#Create the /var/lib/ceph/mon/cluster-node folder with also the upstart file
mkdir /var/lib/ceph/mon/$cluster_name-$HOSTNAME

ceph auth --cluster $cluster_name get mon. -o /tmp/ceph.mon.keyring

ceph mon --cluster $cluster_name getmap -o /tmp/monmap

sudo ceph-mon --cluster $cluster_name -i $HOSTNAME --mkfs --monmap /tmp/monmap --keyring /tmp/ceph.mon.keyring

#Start the "mon" service
ceph-mon -i $HOSTNAME --cluster=$cluster_name

#Add the server to the Monitor Map
ceph mon add $HOSTNAME $ip_addr:6789

#RC LOCAL
sed_line=13
#upstart="sudo start ceph-mon "id=$HOSTNAME" "cluster=$cluster_name""
upstart="ceph-mon -i $HOSTNAME --cluster=$cluster_name"
sudo sed -i "$sed_line a $upstart" /etc/rc.local




####----------------------------------------------------Verification----------------------------###


read -p "We are now going to proceed with the verification. [Press any key]: " fake

echo -e "Verify that Ceph created the default pools"
ceph osd lspools

echo -e "\nVerify that the monitor is running"
ceph -s

#We run the SCP script
bash sources/ceph_scp



